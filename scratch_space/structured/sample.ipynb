{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured output sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI direct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Step(BaseModel):\n",
    "    explanation: str = Field(description=\"Explanation of the step\")\n",
    "    output: str = Field(description=\"Output of the step\")\n",
    "\n",
    "\n",
    "class MathResponse(BaseModel):\n",
    "    steps: list[Step] = Field(description=\"List of steps to solve the math problem\")\n",
    "    final_answer: str = Field(description=\"Final answer of the math problem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful math tutor.\"},\n",
    "        {\"role\": \"user\", \"content\": \"solve 8x + 31 = 2\"},\n",
    "    ],\n",
    "    response_format=MathResponse,\n",
    ")\n",
    "\n",
    "message = completion.choices[0].message\n",
    "if message.parsed:\n",
    "    print(message.parsed.steps)\n",
    "    print(message.parsed.final_answer)\n",
    "else:\n",
    "    print(message.refusal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Joke(BaseModel):\n",
    "#     setup: str = Field(description=\"The setup of the joke\")\n",
    "#     punchline: str = Field(description=\"The punchline to the joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "structured_llm = model.with_structured_output(MathResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structured_llm.invoke(\"Tell me a joke about cats\")\n",
    "output = structured_llm.invoke(\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful math tutor.\"},\n",
    "        {\"role\": \"user\", \"content\": \"solve 8x + 31 = 2\"},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output: MathResponse = output  # type: ignore\n",
    "if not isinstance(output, MathResponse):\n",
    "    raise ValueError(\"Expected MathResponse but got something else\")\n",
    "for step in output.steps:\n",
    "    print(step.explanation)\n",
    "    print(step.output)\n",
    "print(output.final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convo_craft.llm.converse import Conversation\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "structured_llm = model.with_structured_output(Conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm = HumanMessage(\n",
    "    \"\"\"Write a conversation in brazilian portuguese between two persons, \\\n",
    "that should be used to teach the user the language.\n",
    "The conversation should be about the following topic: \"How to order food in a restaurant\".\n",
    "Assume that the user has an intermediate level of understanding of the language.\n",
    "The conversation should last about 10 messages in total, with each message being about 2-3 sentences long.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo = structured_llm.invoke([hm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isinstance(convo, Conversation):\n",
    "    raise ValueError(\"Expected Conversation but got something else\")\n",
    "\n",
    "for turn in convo.turns:\n",
    "    print(turn.role)\n",
    "    print(turn.content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the hm into a prompt\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import (\n",
    "    ChatMessagePromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    StringPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_template = \"\"\"Write a conversation in {language} between two persons, \\\n",
    "that should be used to teach the user the language.\n",
    "The conversation should be about the following topic: \"{topic}\".\n",
    "Assume that the user has an intermediate level of understanding of the language.\n",
    "The conversation should last about {num_msg} messages in total, with each message being about 2-3 sentences long.\n",
    "\"\"\"\n",
    "converse_prompt = ChatPromptTemplate(\n",
    "    [HumanMessagePromptTemplate.from_template(convo_template)]\n",
    ")\n",
    "converse_value = converse_prompt.invoke(\n",
    "    {\n",
    "        \"language\": \"brazilian portuguese\",\n",
    "        \"topic\": \"How to order food in a restaurant\",\n",
    "        \"num_msg\": \"10\",\n",
    "    }\n",
    ")\n",
    "print(converse_value.to_messages()[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convo_craft.llm.converse import CONVERSATION_SAMPLE, ConversationGenerator\n",
    "\n",
    "\n",
    "cg = ConversationGenerator(\n",
    "    language=\"brazilian portuguese\",\n",
    "    num_msg=10,\n",
    "    understanding_level=\"intermediate\",\n",
    "    conversation_sample=CONVERSATION_SAMPLE,\n",
    ")\n",
    "# conv = cg.invoke(\"A conversation about ordering food in a restaurant.\")\n",
    "conv = cg.invoke(\"A conversation about traveling to a foreign country.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for turn in conv.turns:\n",
    "    print(turn.content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convo_craft.llm.translate import Translator\n",
    "\n",
    "\n",
    "tr = Translator(\n",
    "    source_language=\"brazilian portuguese\",\n",
    "    target_language=\"english\",\n",
    ")\n",
    "translation = tr.invoke(\"Eu gosto de comer pizza.\")\n",
    "translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convo_craft.llm.split_paragraph import ParagraphSplitter\n",
    "\n",
    "\n",
    "ps = ParagraphSplitter()\n",
    "orig = \"Eu gosto de comer pizza. Eu também gosto de comer hambúrguer. Assim como gosto de comer batata frita.\"\n",
    "split = ps.invoke(orig)\n",
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebuild = \" \".join(split.portions)\n",
    "rebuild == orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic picker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convo_craft.llm.topic_picker import OLD_TOPICS, TopicPicker\n",
    "\n",
    "\n",
    "tp = TopicPicker(\n",
    "    language=\"brazilian portuguese\",\n",
    "    understanding_level=\"intermediate\",\n",
    ")\n",
    "topics = tp.invoke(OLD_TOPICS)\n",
    "for topic in topics.topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence splitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convo_craft.text.split_sentence import SentenceSplitter\n",
    "\n",
    "\n",
    "ss = SentenceSplitter()\n",
    "words = ss.invoke(\"I like to eat pizza. I also like to eat hamburgers.\")\n",
    "print(\" | \".join(words))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "convo-craft-5cDUP2Ok-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
